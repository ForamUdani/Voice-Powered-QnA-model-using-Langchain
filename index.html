<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice-Powered QA Chatbot</title>
    <!-- Tailwind CSS CDN for easy styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Font Awesome for microphone icon -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f3f4f6; /* Light gray background */
        }
        .container {
            max-width: 800px;
            margin: 2rem auto;
            background-color: #ffffff;
            border-radius: 1rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            padding: 2rem;
        }
        .mic-button, .send-button {
            transition: background-color 0.3s ease, transform 0.1s ease;
        }
        .mic-button:hover, .send-button:hover {
            background-color: #4f46e5; /* Darker indigo on hover */
        }
        .mic-button:active, .send-button:active {
            transform: scale(0.98);
        }
        .mic-button.recording {
            background-color: #ef4444; /* Red when recording */
            animation: pulse 1.5s infinite;
        }
        .mic-button.recording:hover {
            background-color: #dc2626; /* Darker red on hover when recording */
        }
        .mic-button.speaking {
            background-color: #10b981; /* Green when AI is speaking */
        }
        .mic-button.speaking:hover {
            background-color: #059669; /* Darker green on hover when speaking */
        }

        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(99, 102, 241, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(99, 102, 241, 0); }
            100% { box-shadow: 0 0 0 0 rgba(99, 102, 241, 0); }
        }
        .loading-spinner {
            border: 4px solid rgba(0, 0, 0, 0.1);
            border-left-color: #6366f1;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .chat-message {
            margin-bottom: 1rem;
            padding: 0.75rem 1rem;
            border-radius: 0.75rem;
            max-width: 80%;
        }
        .user-message {
            background-color: #e0e7ff; /* Light blue for user */
            align-self: flex-end;
            margin-left: auto;
        }
        .ai-message {
            background-color: #f3f4f6; /* Light gray for AI */
            align-self: flex-start;
            margin-right: auto;
        }
    </style>
</head>
<body class="p-4">
    <div class="container flex flex-col space-y-6">
        <h1 class="text-3xl font-bold text-center text-indigo-700 mb-6">Voice-Powered QA Chatbot</h1>

        <!-- Chat History Display -->
        <div id="chat-history" class="flex flex-col space-y-4 h-96 overflow-y-auto p-4 bg-gray-50 rounded-lg border border-gray-200">
            <!-- Chat messages will be appended here -->
        </div>

        <!-- Query Input, Microphone Button, and Send Button -->
        <div class="flex items-center space-x-4">
            <textarea
                id="query-input"
                class="flex-grow p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-indigo-500 focus:border-transparent outline-none resize-none"
                rows="3"
                placeholder="Type your question or press the mic to speak..."
            ></textarea>
            <button
                id="mic-button"
                class="mic-button bg-indigo-600 text-white p-4 rounded-full shadow-lg flex items-center justify-center focus:outline-none focus:ring-2 focus:ring-indigo-500"
                title="Start speaking"
            >
                <i class="fas fa-microphone text-2xl"></i>
            </button>
            <button
                id="send-button"
                class="send-button bg-indigo-600 text-white p-4 rounded-full shadow-lg flex items-center justify-center focus:outline-none focus:ring-2 focus:ring-indigo-500"
                title="Send query"
            >
                <i class="fas fa-paper-plane text-2xl"></i>
            </button>
        </div>

        <!-- Status Indicators -->
        <div id="status-display" class="text-center text-gray-600 font-medium">
            <!-- Dynamic status messages like "Listening...", "Processing...", etc. -->
        </div>

        <!-- Loading Indicator (for processing/thinking) -->
        <div id="loading-indicator" class="hidden flex items-center justify-center space-x-2 text-indigo-600">
            <div class="loading-spinner"></div>
            <span>Processing query...</span>
        </div>
         <!-- Speaking Indicator -->
        <div id="speaking-indicator" class="hidden flex items-center justify-center space-x-2 text-green-600">
            <i class="fas fa-volume-up text-xl"></i>
            <span>AI is speaking...</span>
        </div>

        <!-- Source Documents Display -->
        <div id="source-documents" class="hidden mt-4 p-4 bg-gray-100 rounded-lg border border-gray-200">
            <h3 class="text-lg font-semibold text-gray-800 mb-2">Source Documents:</h3>
            <ul id="source-list" class="list-disc pl-5 text-gray-700 text-sm">
                <!-- Source documents will be appended here -->
            </ul>
        </div>
    </div>

    <script>
        // Get references to DOM elements
        const queryInput = document.getElementById('query-input');
        const micButton = document.getElementById('mic-button');
        const sendButton = document.getElementById('send-button'); // New send button
        const statusDisplay = document.getElementById('status-display'); // New status display
        const loadingIndicator = document.getElementById('loading-indicator');
        const speakingIndicator = document.getElementById('speaking-indicator');
        const chatHistoryDiv = document.getElementById('chat-history');
        const sourceDocumentsDiv = document.getElementById('source-documents');
        const sourceList = document.getElementById('source-list');

        let recognition; // SpeechRecognition object
        let isRecording = false;
        let chatHistory = []; // Stores conversation history for the backend: List of [human_message, ai_message] tuples
        let synth = window.speechSynthesis; // SpeechSynthesis object
        let voices = []; // Array to store available voices

        // Function to populate voices
        function populateVoices() {
            voices = synth.getVoices();
            console.log("Available voices:", voices.map(v => v.name));
        }

        // Populate voices when they are loaded (async)
        if (synth.onvoiceschanged !== undefined) {
            synth.onvoiceschanged = populateVoices;
        } else {
            populateVoices(); // Fallback for browsers that don't fire onvoiceschanged immediately
        }

        // --- UI Feedback Functions ---
        function setStatus(message) {
            statusDisplay.textContent = message;
        }

        function showLoading() {
            loadingIndicator.classList.remove('hidden');
            loadingIndicator.classList.add('flex');
            setStatus('Processing query...'); // Update status display
        }

        function hideLoading() {
            loadingIndicator.classList.add('hidden');
            loadingIndicator.classList.remove('flex');
            setStatus(''); // Clear status when not loading
        }

        function showSpeaking() {
            speakingIndicator.classList.remove('hidden');
            speakingIndicator.classList.add('flex');
            micButton.classList.add('speaking');
            sendButton.disabled = true; // Disable send button while AI is speaking
            setStatus('AI is speaking...'); // Update status display
        }

        function hideSpeaking() {
            speakingIndicator.classList.add('hidden');
            speakingIndicator.classList.remove('flex');
            micButton.classList.remove('speaking');
            sendButton.disabled = false; // Re-enable send button
            setStatus(''); // Clear status when not speaking
        }
        // --- End UI Feedback Functions ---


        // Check for Web Speech API compatibility
        if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
            micButton.disabled = true;
            micButton.title = "Speech recognition not supported in this browser.";
            micButton.classList.add('opacity-50', 'cursor-not-allowed');
            alert("Speech recognition is not supported in your browser. Please use Google Chrome for this feature.");
            sendButton.disabled = false; // Ensure send button is still active for typing
        } else {
            // Initialize SpeechRecognition
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = true; // Set to true for interim results
            recognition.interimResults = true; // Get interim results
            recognition.lang = 'en-US';

            // Event handler for when speech recognition starts
            recognition.onstart = () => {
                isRecording = true;
                micButton.classList.add('recording');
                micButton.classList.remove('speaking');
                micButton.innerHTML = '<i class="fas fa-microphone-slash text-2xl"></i>';
                micButton.title = "Stop speaking";
                queryInput.placeholder = "Listening...";
                sendButton.disabled = true; // Disable send button while listening
                hideSpeaking(); // Hide speaking indicator if it was active
                setStatus('Listening...');
                console.log('Speech recognition started');
            };

            // Event handler for when speech recognition ends
            recognition.onend = () => {
                isRecording = false;
                micButton.classList.remove('recording');
                micButton.innerHTML = '<i class="fas fa-microphone text-2xl"></i>';
                micButton.title = "Start speaking";
                queryInput.placeholder = "Type your question or press the mic to speak...";
                sendButton.disabled = false; // Re-enable send button after listening
                setStatus(''); // Clear listening status
                console.log('Speech recognition ended');
            };

            // Event handler for when a speech recognition result is available
            recognition.onresult = (event) => {
                let interimTranscript = '';
                let finalTranscript = '';

                for (let i = 0; i < event.results.length; ++i) {
                    if (event.results[i].isFinal) {
                        finalTranscript += event.results[i][0].transcript;
                    } else {
                        interimTranscript += event.results[i][0].transcript;
                    }
                }
                // Display both final and interim results
                queryInput.value = finalTranscript + interimTranscript;
                console.log('Interim:', interimTranscript, 'Final:', finalTranscript);
                // IMPORTANT: The query is NO LONGER sent automatically here.
                // User must click "Send" or press Enter.
            };

            // Event handler for speech recognition errors
            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                if (event.error === 'no-speech') {
                    setStatus('No speech detected. Please try again.');
                } else if (event.error === 'not-allowed') {
                    alert('Microphone access denied. Please allow microphone access in your browser settings.');
                    setStatus('Microphone access denied.');
                } else {
                    setStatus('Speech recognition error: ' + event.error);
                }
                isRecording = false;
                micButton.classList.remove('recording');
                micButton.innerHTML = '<i class="fas fa-microphone text-2xl"></i>';
                micButton.title = "Start speaking";
                queryInput.placeholder = "Type your question or press the mic to speak...";
                sendButton.disabled = false; // Re-enable send button on error
                hideLoading();
            };

            // Toggle speech recognition on mic button click
            micButton.addEventListener('click', () => {
                if (isRecording) {
                    recognition.stop();
                } else if (synth.speaking) {
                    // If AI is speaking, stop it first, then start listening
                    synth.cancel();
                    hideSpeaking();
                    recognition.start();
                } else {
                    queryInput.value = ''; // Clear previous query before listening
                    recognition.start();
                }
            });
        }

        // Function to speak the AI's response
        function speakResponse(text) {
            if (synth.speaking) {
                synth.cancel(); // Stop any ongoing speech
            }

            if ('SpeechSynthesisUtterance' in window) {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = 'en-US';

                const preferredVoice = voices.find(voice => voice.name.includes('Google US English') && !voice.name.includes('Female'));
                if (preferredVoice) {
                    utterance.voice = preferredVoice;
                } else if (voices.length > 0) {
                    utterance.voice = voices[0];
                }

                utterance.onstart = () => {
                    showSpeaking();
                    micButton.disabled = true; // Disable mic button while AI is speaking
                };
                utterance.onend = () => {
                    hideSpeaking();
                    micButton.disabled = false; // Re-enable mic button after AI finishes speaking
                };
                utterance.onerror = (event) => {
                    console.error('Speech synthesis error:', event.error);
                    hideSpeaking();
                    micButton.disabled = false;
                    setStatus('Speech synthesis error.');
                };

                synth.speak(utterance);
            } else {
                console.warn('SpeechSynthesisUtterance not supported in this browser. AI will not speak.');
                setStatus('Text-to-speech not supported.');
            }
        }


        // Function to send query to the backend
        async function sendQuery(query) {
            if (!query.trim()) {
                setStatus("Please enter or speak a question.");
                return;
            }

            // Stop any ongoing speech before sending new query
            if (synth.speaking) {
                synth.cancel();
                hideSpeaking();
            }
            if (isRecording) { // Stop recording if user hits send while speaking
                recognition.stop();
            }

            addMessageToChat(query, 'user');
            showLoading(); // Show "Processing query..."
            sourceDocumentsDiv.classList.add('hidden'); // Hide previous sources
            sourceList.innerHTML = ''; // Clear previous sources

            try {
                const response = await fetch('http://127.0.0.1:8000/ask', { // Replace with your FastAPI URL if deployed
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        query: query,
                        chat_history: chatHistory
                    }),
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.detail || 'Failed to fetch answer from API');
                }

                const data = await response.json();
                addMessageToChat(data.answer, 'ai');
                chatHistory.push([query, data.answer]);

                speakResponse(data.answer);

                // Display source documents if available
                if (data.source_documents && data.source_documents.length > 0) {
                    sourceDocumentsDiv.classList.remove('hidden');
                    data.source_documents.forEach(doc => {
                        const listItem = document.createElement('li');
                        // Ensure 'metadata' and 'title' exist before accessing
                        const title = doc.metadata && doc.metadata.title ? doc.metadata.title : 'N/A';
                        listItem.innerHTML = `<strong>Title:</strong> ${title}<br>
                                            <strong>Chunk:</strong> ${doc.page_content.substring(0, 200)}...`;
                        sourceList.appendChild(listItem);
                    });
                }

            } catch (error) {
                console.error('Error sending query:', error);
                addMessageToChat(`Error: ${error.message}`, 'ai');
                setStatus(`Error: ${error.message}`);
            } finally {
                hideLoading();
                queryInput.value = ''; // Clear input after sending
            }
        }

        // --- Event Listeners for sending query ---
        // New: Send button click
        sendButton.addEventListener('click', () => {
            sendQuery(queryInput.value);
        });

        // Existing: Allow sending query by pressing Enter in the text area
        queryInput.addEventListener('keypress', (event) => {
            if (event.key === 'Enter' && !event.shiftKey) { // Shift+Enter for new line
                event.preventDefault(); // Prevent default Enter behavior (new line)
                sendQuery(queryInput.value);
            }
        });
        // --- End Event Listeners ---


        // Initial welcome message and speak it
        const welcomeMessage = "Hello! Ask me anything about AI academic papers.";
        addMessageToChat(welcomeMessage, 'ai');
        speakResponse(welcomeMessage);

    </script>
</body>
</html>
