<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice-Powered QA Chatbot</title>
    <!-- Tailwind CSS CDN for easy styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Font Awesome for microphone icon -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f3f4f6; /* Light gray background */
        }
        .container {
            max-width: 800px;
            margin: 2rem auto;
            background-color: #ffffff;
            border-radius: 1rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            padding: 2rem;
        }
        .mic-button, .send-button {
            transition: background-color 0.3s ease, transform 0.1s ease;
        }
        .mic-button:hover, .send-button:hover {
            background-color: #4f46e5; /* Darker indigo on hover */
        }
        .mic-button:active, .send-button:active {
            transform: scale(0.98);
        }
        .mic-button.recording {
            background-color: #ef4444; /* Red when recording */
            animation: pulse 1.5s infinite;
        }
        .mic-button.recording:hover {
            background-color: #dc2626; /* Darker red on hover when recording */
        }
        .mic-button.speaking {
            background-color: #10b981; /* Green when AI is speaking */
        }
        .mic-button.speaking:hover {
            background-color: #059669; /* Darker green on hover when speaking */
        }

        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(99, 102, 241, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(99, 102, 241, 0); }
            100% { box-shadow: 0 0 0 0 rgba(99, 102, 241, 0); }
        }
        .loading-spinner {
            border: 4px solid rgba(0, 0, 0, 0.1);
            border-left-color: #6366f1;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .chat-message {
            margin-bottom: 1rem;
            padding: 0.75rem 1rem;
            border-radius: 0.75rem;
            max-width: 80%;
        }
        .user-message {
            background-color: #e0e7ff; /* Light blue for user */
            align-self: flex-end;
            margin-left: auto;
        }
        .ai-message {
            background-color: #f3f4f6; /* Light gray for AI */
            align-self: flex-start;
            margin-right: auto;
        }
    </style>
</head>
<body class="p-4">
    <div class="container flex flex-col space-y-6">
        <h1 class="text-3xl font-bold text-center text-indigo-700 mb-6">Voice-Powered QA Chatbot</h1>

        <!-- Session ID Display (for debugging/info) -->
        <div class="text-sm text-gray-500 text-center">
            Session ID: <span id="session-id-display">Loading...</span>
        </div>

        <!-- Filters Section -->
        <div class="bg-gray-50 p-4 rounded-lg border border-gray-200">
            <h2 class="text-xl font-semibold text-gray-800 mb-3">Filters (Optional)</h2>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
                <div>
                    <label for="filter-author" class="block text-sm font-medium text-gray-700 mb-1">Author Name:</label>
                    <input type="text" id="filter-author" class="w-full p-2 border border-gray-300 rounded-md focus:ring-indigo-500 focus:border-indigo-500" placeholder="e.g., Victor Sanh">
                </div>
                <div>
                    <label for="filter-year" class="block text-sm font-medium text-gray-700 mb-1">Publication Year:</label>
                    <input type="number" id="filter-year" class="w-full p-2 border border-gray-300 rounded-md focus:ring-indigo-500 focus:border-indigo-500" placeholder="e.g., 2019">
                </div>
            </div>
        </div>

        <!-- Chat History Display -->
        <div id="chat-history" class="flex flex-col space-y-4 h-96 overflow-y-auto p-4 bg-gray-50 rounded-lg border border-gray-200">
            <!-- Chat messages will be appended here -->
        </div>

        <!-- Query Input, Microphone Button, and Send Button -->
        <div class="flex items-center space-x-4">
            <textarea
                id="query-input"
                class="flex-grow p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-indigo-500 focus:border-transparent outline-none resize-none"
                rows="3"
                placeholder="Type your question or press the mic to speak..."
            ></textarea>
            <button
                id="mic-button"
                class="mic-button bg-indigo-600 text-white p-4 rounded-full shadow-lg flex items-center justify-center focus:outline-none focus:ring-2 focus:ring-indigo-500"
                title="Start speaking"
            >
                <i class="fas fa-microphone text-2xl"></i>
            </button>
            <button
                id="send-button"
                class="send-button bg-indigo-600 text-white p-4 rounded-full shadow-lg flex items-center justify-center focus:outline-none focus:ring-2 focus:ring-indigo-500"
                title="Send query"
            >
                <i class="fas fa-paper-plane text-2xl"></i>
            </button>
        </div>

        <!-- Status Indicators -->
        <div id="status-display" class="text-center text-gray-600 font-medium">
            <!-- Dynamic status messages like "Listening...", "Processing...", etc. -->
        </div>

        <!-- Loading Indicator (for processing/thinking) -->
        <div id="loading-indicator" class="hidden flex items-center justify-center space-x-2 text-indigo-600">
            <div class="loading-spinner"></div>
            <span>Processing query...</span>
        </div>
         <!-- Speaking Indicator -->
        <div id="speaking-indicator" class="hidden flex items-center justify-center space-x-2 text-green-600">
            <i class="fas fa-volume-up text-xl"></i>
            <span>AI is speaking...</span>
        </div>

        <!-- Source Documents Display -->
        <div id="source-documents" class="hidden mt-4 p-4 bg-gray-100 rounded-lg border border-gray-200">
            <h3 class="text-lg font-semibold text-gray-800 mb-2">Source Documents:</h3>
            <ul id="source-list" class="list-disc pl-5 text-gray-700 text-sm">
                <!-- Source documents will be appended here -->
            </ul>
        </div>
    </div>

    <script>
        // Get references to DOM elements
        const queryInput = document.getElementById('query-input');
        const micButton = document.getElementById('mic-button');
        const sendButton = document.getElementById('send-button');
        const statusDisplay = document.getElementById('status-display');
        const loadingIndicator = document.getElementById('loading-indicator');
        const speakingIndicator = document.getElementById('speaking-indicator');
        const chatHistoryDiv = document.getElementById('chat-history');
        const sourceDocumentsDiv = document.getElementById('source-documents');
        const sourceList = document.getElementById('source-list');
        const sessionIdDisplay = document.getElementById('session-id-display'); // New element for session ID

        // Filter input elements
        const filterAuthorInput = document.getElementById('filter-author');
        const filterYearInput = document.getElementById('filter-year');

        let recognition;
        let isRecording = false;
        let chatHistory = []; // Now represents the full history from the backend
        let synth = window.speechSynthesis;
        let voices = [];
        let currentSessionId = null; // Store the current session ID


        function populateVoices() {
            voices = synth.getVoices();
            console.log("Available voices:", voices.map(v => v.name));
        }

        if (synth.onvoiceschanged !== undefined) {
            synth.onvoiceschanged = populateVoices;
        } else {
            populateVoices();
        }

        // --- UI Feedback Functions ---
        function setStatus(message) {
            statusDisplay.textContent = message;
        }

        function showLoading() {
            loadingIndicator.classList.remove('hidden');
            loadingIndicator.classList.add('flex');
            setStatus('Processing query...');
        }

        function hideLoading() {
            loadingIndicator.classList.add('hidden');
            loadingIndicator.classList.remove('flex');
            setStatus('');
        }

        function showSpeaking() {
            speakingIndicator.classList.remove('hidden');
            speakingIndicator.classList.add('flex');
            micButton.classList.add('speaking');
            sendButton.disabled = true;
            queryInput.disabled = true;
            setStatus('AI is speaking...');
        }

        function hideSpeaking() {
            speakingIndicator.classList.add('hidden');
            speakingIndicator.classList.remove('flex');
            micButton.classList.remove('speaking');
            sendButton.disabled = false;
            queryInput.disabled = false;
            setStatus('');
        }
        // --- End UI Feedback Functions ---


        // Check for Web Speech API compatibility
        if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
            micButton.disabled = true;
            micButton.title = "Speech recognition not supported in this browser.";
            micButton.classList.add('opacity-50', 'cursor-not-allowed');
            setStatus('Speech recognition not supported in this browser.');
            sendButton.disabled = false;
        } else {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                isRecording = true;
                micButton.classList.add('recording');
                micButton.classList.remove('speaking');
                micButton.innerHTML = '<i class="fas fa-microphone-slash text-2xl"></i>';
                micButton.title = "Stop speaking";
                queryInput.placeholder = "Listening...";
                sendButton.disabled = true;
                queryInput.disabled = true;
                hideSpeaking();
                setStatus('Listening...');
                console.log('Speech recognition started');
            };

            recognition.onend = () => {
                isRecording = false;
                micButton.classList.remove('recording');
                micButton.innerHTML = '<i class="fas fa-microphone text-2xl"></i>';
                micButton.title = "Start speaking";
                queryInput.placeholder = "Type your question or press the mic to speak...";
                sendButton.disabled = false;
                queryInput.disabled = false;
                setStatus('');
                console.log('Speech recognition ended');
            };

            recognition.onresult = (event) => {
                let interimTranscript = '';
                let finalTranscript = '';

                for (let i = 0; i < event.results.length; ++i) {
                    if (event.results[i].isFinal) {
                        finalTranscript += event.results[i][0].transcript;
                    } else {
                        interimTranscript += event.results[i][0].transcript;
                    }
                }
                queryInput.value = finalTranscript + interimTranscript;
                console.log('Interim:', interimTranscript, 'Final:', finalTranscript);
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                if (event.error === 'no-speech') {
                    setStatus('No speech detected. Please try again.');
                } else if (event.error === 'not-allowed') {
                    alert('Microphone access denied. Please allow microphone access in your browser settings.');
                    setStatus('Microphone access denied.');
                } else {
                    setStatus('Speech recognition error: ' + event.error);
                }
                isRecording = false;
                micButton.classList.remove('recording');
                micButton.innerHTML = '<i class="fas fa-microphone text-2xl"></i>';
                micButton.title = "Start speaking";
                queryInput.placeholder = "Type your question or press the mic to speak...";
                sendButton.disabled = false;
                queryInput.disabled = false;
                hideLoading();
            };

            micButton.addEventListener('click', () => {
                if (isRecording) {
                    recognition.stop();
                } else if (synth.speaking) {
                    synth.cancel();
                    hideSpeaking();
                    recognition.start();
                } else {
                    queryInput.value = '';
                    recognition.start();
                }
            });
        }

        function speakResponse(text) {
            if (synth.speaking) {
                synth.cancel();
            }

            if ('SpeechSynthesisUtterance' in window) {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = 'en-US';

                const preferredVoice = voices.find(voice => voice.name.includes('Google US English') && !voice.name.includes('Female'));
                if (preferredVoice) {
                    utterance.voice = preferredVoice;
                } else if (voices.length > 0) {
                    utterance.voice = voices[0];
                }

                utterance.onstart = () => {
                    showSpeaking();
                    micButton.disabled = true;
                };
                utterance.onend = () => {
                    hideSpeaking();
                    micButton.disabled = false;
                };
                utterance.onerror = (event) => {
                    console.error('Speech synthesis error:', event.error);
                    hideSpeaking();
                    micButton.disabled = false;
                    setStatus('Speech synthesis error.');
                };

                synth.speak(utterance);
            } else {
                console.warn('SpeechSynthesisUtterance not supported in this browser. AI will not speak.');
                setStatus('Text-to-speech not supported.');
            }
        }

        function addMessageToChat(text, sender) {
            const messageDiv = document.createElement('div');
            messageDiv.classList.add('chat-message', sender === 'user' ? 'user-message' : 'ai-message');
            messageDiv.textContent = text;
            chatHistoryDiv.appendChild(messageDiv);
            chatHistoryDiv.scrollTop = chatHistoryDiv.scrollHeight;
        }

        async function sendQuery(query) {
            if (!query.trim()) {
                setStatus("Please enter or speak a question.");
                return;
            }

            if (synth.speaking) {
                synth.cancel();
                hideSpeaking();
            }
            if (isRecording) {
                recognition.stop();
            }

            addMessageToChat(query, 'user');
            showLoading();
            sourceDocumentsDiv.classList.add('hidden');
            sourceList.innerHTML = '';

            const filters = {};
            const author = filterAuthorInput.value.trim();
            const year = filterYearInput.value.trim();

            if (author) {
                filters.author = author;
            }
            if (year) {
                filters.publication_year = year;
            }
            console.log("Sending query with filters:", filters, "Session ID:", currentSessionId);

            try {
                const response = await fetch('http://127.0.0.1:8000/ask', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        session_id: currentSessionId, // Send the current session ID
                        query: query,
                        chat_history: chatHistory, // Still sending the current chatHistory, backend will merge with Firestore
                        filters: Object.keys(filters).length > 0 ? filters : null
                    }),
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.detail || 'Failed to fetch answer from API');
                }

                const data = await response.json();
                addMessageToChat(data.answer, 'ai');
                // Backend returns the full updated chat history, we'll update our client-side state
                // This is a simplified approach, a more robust solution might retrieve full history or append based on session_id returned.
                // For now, we assume the backend correctly persists and returns the state.
                // A better approach would be to refetch history after each `ask` call.
                // However, since we're using current `chatHistory` for UI and backend handles full persistence, we just append for local view.
                chatHistory.push([query, data.answer]); // Update local view of chat history

                speakResponse(data.answer);

                if (data.source_documents && data.source_documents.length > 0) {
                    sourceDocumentsDiv.classList.remove('hidden');
                    data.source_documents.forEach(doc => {
                        const listItem = document.createElement('li');
                        const title = doc.metadata && doc.metadata.title ? doc.metadata.title : 'N/A';
                        const authorMeta = doc.metadata && doc.metadata.first_author ? ` by ${doc.metadata.first_author}` : '';
                        const yearMeta = doc.metadata && doc.metadata.publication_year ? ` (${doc.metadata.publication_year})` : '';

                        listItem.innerHTML = `<strong>Title:</strong> ${title}${authorMeta}${yearMeta}<br>
                                            <strong>Chunk:</strong> ${doc.page_content.substring(0, Math.min(doc.page_content.length, 200))}...`;
                        sourceList.appendChild(listItem);
                    });
                }

            } catch (error) {
                console.error('Error sending query:', error);
                addMessageToChat(`Error: ${error.message}`, 'ai');
                setStatus(`Error: ${error.message}`);
            } finally {
                hideLoading();
                queryInput.value = '';
            }
        }

        // --- Session Management ---
        function getOrCreateSessionId() {
            let sessionId = localStorage.getItem('chat_session_id');
            if (!sessionId) {
                sessionId = crypto.randomUUID(); // Generate a new UUID
                localStorage.setItem('chat_session_id', sessionId);
            }
            currentSessionId = sessionId;
            sessionIdDisplay.textContent = sessionId; // Display it in the UI
            console.log("Current Session ID:", currentSessionId);
            return sessionId;
        }

        async function loadChatHistory() {
            const sessionId = getOrCreateSessionId();
            setStatus("Loading chat history...");
            try {
                const response = await fetch(`http://127.0.0.1:8000/get_history?session_id=${sessionId}`);
                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.detail || 'Failed to load chat history');
                }
                const data = await response.json();
                chatHistory = data.chat_history; // Update global chatHistory
                console.log("Loaded chat history:", chatHistory);

                if (chatHistory.length === 0) {
                    const welcomeMessage = "Hello! Ask me anything about AI academic papers.";
                    addMessageToChat(welcomeMessage, 'ai');
                    speakResponse(welcomeMessage);
                } else {
                    chatHistory.forEach(([human_msg, ai_msg]) => {
                        addMessageToChat(human_msg, 'user');
                        addMessageToChat(ai_msg, 'ai');
                    });
                    setStatus("History loaded.");
                }

            } catch (error) {
                console.error("Error loading chat history:", error);
                setStatus(`Error loading history: ${error.message}`);
                // If history load fails, start a new session visually
                const welcomeMessage = "Welcome! Had trouble loading past history, starting a new chat. Ask me anything about AI academic papers.";
                addMessageToChat(welcomeMessage, 'ai');
                speakResponse(welcomeMessage);
            } finally {
                hideLoading(); // Ensure loading indicator is off
            }
        }

        // --- Event Listeners ---
        sendButton.addEventListener('click', () => {
            sendQuery(queryInput.value);
        });

        queryInput.addEventListener('keypress', (event) => {
            if (event.key === 'Enter' && !event.shiftKey) {
                event.preventDefault();
                sendQuery(queryInput.value);
            }
        });

        // Initialize filter inputs to be enabled
        filterAuthorInput.disabled = false;
        filterYearInput.disabled = false;

        // Load chat history when the page loads
        document.addEventListener('DOMContentLoaded', loadChatHistory);

    </script>
</body>
</html>
